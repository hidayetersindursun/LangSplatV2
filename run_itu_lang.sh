#!/bin/bash

# KullanÄ±m (Arka planda Ã§alÄ±ÅŸtÄ±rmak iÃ§in):
# nohup ./run_itu_lang.sh > logs/train_lang_itu.log 2>&1 &
#
# LoglarÄ± takip etmek iÃ§in:
# tail -f logs/train_lang_itu.log

# Dataset ve Yollar
DATASET_PATH="custom_datasets/preprocess-itu"
DATASET_NAME="itu"
RGB_OUTPUT_DIR="output/${DATASET_NAME}_rgb"
RGB_CKPT_PATH="${RGB_OUTPUT_DIR}_-1/chkpnt30000.pth"

# 1. RGB Checkpoint KontrolÃ¼
if [ ! -f "$RGB_CKPT_PATH" ]; then
    echo "âŒ HATA: RGB Checkpoint bulunamadÄ±: $RGB_CKPT_PATH"
    echo "LÃ¼tfen Ã¶nce RGB eÄŸitiminin (run_itu_rgb.sh) tamamlandÄ±ÄŸÄ±ndan emin olun."
    exit 1
fi

echo "ğŸ¯ RGB Checkpoint bulundu: $RGB_CKPT_PATH"

# 2. Feature Training (Level 0, 1, 2)
# Her seviye aynÄ± RGB checkpoint'inden baÅŸlar ve baÄŸÄ±msÄ±z eÄŸitilir.
# -r 2 parametresi (yarÄ± Ã§Ã¶zÃ¼nÃ¼rlÃ¼k) kullanÄ±lÄ±yor.

for level in 0 1 2
do
    echo "ğŸ§  [Level ${level}] Dil Ã–zellikleri EÄŸitimi BaÅŸlÄ±yor..."
    python train.py \
        -s $DATASET_PATH \
        -m output/${DATASET_NAME}_lang_${level} \
        --start_checkpoint $RGB_CKPT_PATH \
        --include_feature \
        --feature_level ${level} \
        --iterations 30000 \
        --save_iterations 30000 \
        --checkpoint_iterations 30000 \
        --vq_layer_num 1 \
        --codebook_size 64 \
        --cos_loss \
        --topk 4 \
        --debug_interval 1000 \
        -r 2
        
    echo "âœ… Level ${level} TamamlandÄ±."
done

echo "ğŸ‰ TÃ¼m Dil EÄŸitimleri TamamlandÄ±!"
